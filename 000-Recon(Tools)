ğŸ—²ğŸ—²ğŸ—²INFORMATION GATHERING (Subdomain, Directory, IP, Port)ğŸ—²ğŸ—²ğŸ—²

#Subfinder (https://github.com/projectdiscovery/subfinder)
  ğŸ—²subfinder -d target.com
  ğŸ—²subfinder -d target.com -o subs.txt
  ğŸ—²subfinder -d target.com -silent -o subs.txt | httpx -title -content-length -status-code -silent

#Knockpy (https://github.com/guelfoweb/knock)
  ğŸ—²python3 knockpy.py target.com
  ğŸ—²python3 knockpy.py target.com | tee subs.txt

#Crtsh (https://github.com/YashGoti/crtsh)
  ğŸ—²python3 crtsh.py -d target.com

#Amass (https://github.com/owasp-amass/amass)
  ğŸ—²amass enum -passive -d target.com
  ğŸ—²amass enum -brute -d target.com
  ğŸ—²amass enum -o amass.txt -d target.com
  ğŸ—²amass enum -brute -active -d target.com -o amass.txt


#CurL
  Subdomain enemuration
  ğŸ—²curl --silent https://crt.sh/\?q\=%.target.com | sed 's/<\/\?[^>]\+>//g' | grep -i target.com | tail -n +9 | cut -d ">" -f2 | cut -d "<" -f1

#Waybackurls (https://github.com/tomnomnom/waybackurls)
  ğŸ—²waybackurls example.com > urls.txt | grep -oP â€˜(?<=\?|&)\w+(?==|&)â€™ urls.txt | sort -u
  ğŸ—²echo 'target.com' | waybackurls -dates
  ğŸ—²
  ğŸ—²https://web.archive.org/cdx/search/cdx?url=*.target.com&fl=original&collapse=urlkey

#Gau (https://github.com/lc/gau)
  ğŸ—²gau --subs --threads 3 --mc 200 --o urls.txt target.com
  ğŸ—²echo â€œexample.comâ€ | gau | grep .js | httpx -mc 200
  ğŸ—²cat domains.txt | gau --threads 5

ğŸ—²  ğŸ—²  ğŸ—²  ğŸ—²  ğŸ—²  ğŸ—²
#Httpx (https://github.com/projectdiscovery/httpx)
  ğŸ—²cat subdomains.txt | httpx -title -content-length -status-code -silent
  ğŸ—²httpx -l subdomains.txt -ports 80,8080,8000,8888 -threads 200 > subdomains_alive.txt

#Httprobe (https://github.com/tomnomnom/httprobe)
  ğŸ—²cat subdomains.txt | httprobe | tee -a subdomains_alive.txt
  ğŸ—²cat subdomains.txt | httprobe -p http:81 -p http:3000 -p https:3000 -p http:3001 -p https:3001 -p http:8000 -p http:8080 -p https:8443 -c 50 | tee subdomains_alive.txt

ğŸ—²  ğŸ—²  ğŸ—²  ğŸ—²  ğŸ—²  ğŸ—²
#Dirsearch (https://github.com/maurosoria/dirsearch)
  ğŸ—²dirsearch -u target.com
  ğŸ—²dirsearch -L allsubdomains.txt
  ğŸ—²dirsearch -L allsubdomains.txt -e json,html -r -x 500,400 -t 100
  ğŸ—²dirsearch -L allsubdomains.txt -e json,html -r -x 500,400 -t 100 -w /home/wordlists/common.txt

#Fuff (https://github.com/ffuf/ffuf)
  ğŸ—²ffuf -w /home/wordlists/common.txt -u https://target.com/FUZZ -e .php,.php.bak,.js,.json,.txt,.sql,.tar.gz,.bkp,.html,.htm,.zip -mc 200,301 -ac
  ğŸ—²ffuf -u https://targett.com/FUZZ -w /usr/share/wordlists/dirb/common.txt/
  ğŸ—²ffuf -u https://target.com/admin/FUZZ -w /home/wordlists/common.txt -mc 200
  ğŸ—²ffuf -w /home/wordlists/common.txt -u https://target.com/FUZZ -fs 1111 => does not show sizes 1111

#Paramspider (https://github.com/devanshbatham/ParamSpider)
  Discover directories for a single domain:
  ğŸ—²paramspider -d example.com
  Discover URLs for multiple domains from a file:
  ğŸ—²paramspider -l domains.txt

  ğŸ—²paramspider -d target.com --exclude png,jpg,gif,jpeg,swf,woff,gif,svg --level high --quiet -o result.txt

#Feroxbuster (https://github.com/epi052/feroxbuster)
  ğŸ—²./feroxbuster --url http://target.com --wordlist /home/wordlist/big.txt


  











